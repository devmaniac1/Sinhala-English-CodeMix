{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (for Colab)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c7510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c6a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load quality filtered dataset\n",
    "FILTERED_PATH = '/content/drive/MyDrive/HIN_SIN/dataset/quality_filtered.csv'\n",
    "filtered_df = pd.read_csv(FILTERED_PATH, encoding='utf-8')\n",
    "print(f\"Quality filtered samples: {len(filtered_df)}\")\n",
    "\n",
    "# Load human validated sample (if available)\n",
    "try:\n",
    "    VALIDATED_PATH = '/content/drive/MyDrive/HIN_SIN/annotations/human_validated_sample.csv'\n",
    "    validated_df = pd.read_csv(VALIDATED_PATH, encoding='utf-8')\n",
    "    print(f\"Human validated samples: {len(validated_df)}\")\n",
    "    has_validation = True\n",
    "except:\n",
    "    print(\"No human validation data found. Proceeding without it.\")\n",
    "    has_validation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feaddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If human validation exists, identify samples to remove\n",
    "samples_to_remove = set()\n",
    "\n",
    "if has_validation:\n",
    "    # Remove samples where:\n",
    "    # 1. Intent was NOT preserved\n",
    "    # 2. Code-mixing was NOT natural\n",
    "    # 3. Both annotators disagreed with ground truth\n",
    "    \n",
    "    for idx, row in validated_df.iterrows():\n",
    "        remove = False\n",
    "        \n",
    "        # Check intent preservation\n",
    "        if 'Intent_Preserved' in row and row['Intent_Preserved'] == 'No':\n",
    "            remove = True\n",
    "        \n",
    "        # Check code-mixing naturalness\n",
    "        if 'CodeMix_Natural' in row and row['CodeMix_Natural'] == 'No':\n",
    "            remove = True\n",
    "        \n",
    "        # Check if both annotators disagreed with ground truth\n",
    "        if 'Label_Annotator1' in row and 'Label_Annotator2' in row:\n",
    "            a1 = row['Label_Annotator1']\n",
    "            a2 = row['Label_Annotator2']\n",
    "            gt = row['Label']\n",
    "            if a1 != gt and a2 != gt:\n",
    "                remove = True\n",
    "        \n",
    "        if remove:\n",
    "            samples_to_remove.add(row['ID'])\n",
    "    \n",
    "    print(f\"Samples flagged for removal from validation: {len(samples_to_remove)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663f94cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final dataset\n",
    "final_df = filtered_df[~filtered_df['ID'].isin(samples_to_remove)].copy()\n",
    "\n",
    "print(f\"\\n=== Dataset Size Progression ===\")\n",
    "print(f\"After quality filtering: {len(filtered_df)}\")\n",
    "print(f\"Removed by validation: {len(samples_to_remove)}\")\n",
    "print(f\"Final dataset size: {len(final_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda2dd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare final dataset columns\n",
    "# Standard format for the Sinhala-English cyberbullying dataset\n",
    "\n",
    "final_columns = {\n",
    "    'ID': 'id',\n",
    "    'Text_SinhalaEnglish': 'text',\n",
    "    'Label': 'label'\n",
    "}\n",
    "\n",
    "# Rename and select columns\n",
    "if 'Text_SinhalaEnglish' in final_df.columns:\n",
    "    text_col = 'Text_SinhalaEnglish'\n",
    "elif 'Translated_Text' in final_df.columns:\n",
    "    text_col = 'Translated_Text'\n",
    "else:\n",
    "    text_col = final_df.columns[final_df.columns.str.contains('Text', case=False)][0]\n",
    "\n",
    "output_df = final_df[['ID', text_col, 'Label']].copy()\n",
    "output_df.columns = ['id', 'text', 'label']\n",
    "\n",
    "# Reset index\n",
    "output_df = output_df.reset_index(drop=True)\n",
    "output_df['id'] = range(1, len(output_df) + 1)\n",
    "\n",
    "print(f\"Final dataset shape: {output_df.shape}\")\n",
    "output_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81071dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL DATASET STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nTotal samples: {len(output_df)}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "label_counts = output_df['label'].value_counts()\n",
    "print(f\"  Non-bullying (0): {label_counts[0]} ({label_counts[0]/len(output_df):.1%})\")\n",
    "print(f\"  Bullying (1): {label_counts[1]} ({label_counts[1]/len(output_df):.1%})\")\n",
    "\n",
    "# Text length statistics\n",
    "output_df['text_length'] = output_df['text'].str.len()\n",
    "output_df['word_count'] = output_df['text'].str.split().str.len()\n",
    "\n",
    "print(f\"\\nText length (characters):\")\n",
    "print(f\"  Mean: {output_df['text_length'].mean():.1f}\")\n",
    "print(f\"  Min: {output_df['text_length'].min()}\")\n",
    "print(f\"  Max: {output_df['text_length'].max()}\")\n",
    "\n",
    "print(f\"\\nWord count:\")\n",
    "print(f\"  Mean: {output_df['word_count'].mean():.1f}\")\n",
    "print(f\"  Min: {output_df['word_count'].min()}\")\n",
    "print(f\"  Max: {output_df['word_count'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737e029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Sinhala content\n",
    "import re\n",
    "\n",
    "def has_sinhala(text):\n",
    "    \"\"\"Check if text contains Sinhala characters.\"\"\"\n",
    "    sinhala_pattern = re.compile(r'[\\u0D80-\\u0DFF]')\n",
    "    return bool(sinhala_pattern.search(str(text)))\n",
    "\n",
    "def has_english(text):\n",
    "    \"\"\"Check if text contains English characters.\"\"\"\n",
    "    return bool(re.search(r'[a-zA-Z]', str(text)))\n",
    "\n",
    "output_df['has_sinhala'] = output_df['text'].apply(has_sinhala)\n",
    "output_df['has_english'] = output_df['text'].apply(has_english)\n",
    "output_df['is_code_mixed'] = output_df['has_sinhala'] & output_df['has_english']\n",
    "\n",
    "print(\"\\nCode-mixing analysis:\")\n",
    "print(f\"  Has Sinhala: {output_df['has_sinhala'].sum()} ({output_df['has_sinhala'].mean():.1%})\")\n",
    "print(f\"  Has English: {output_df['has_english'].sum()} ({output_df['has_english'].mean():.1%})\")\n",
    "print(f\"  Code-mixed (both): {output_df['is_code_mixed'].sum()} ({output_df['is_code_mixed'].mean():.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671c23e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove temporary analysis columns\n",
    "output_df = output_df[['id', 'text', 'label']]\n",
    "\n",
    "# View final samples\n",
    "print(\"\\n=== Sample Entries ===\")\n",
    "print(\"\\n--- Non-bullying samples ---\")\n",
    "for _, row in output_df[output_df['label'] == 0].head(3).iterrows():\n",
    "    print(f\"  [{row['id']}] {row['text']}\")\n",
    "\n",
    "print(\"\\n--- Bullying samples ---\")\n",
    "for _, row in output_df[output_df['label'] == 1].head(3).iterrows():\n",
    "    print(f\"  [{row['id']}] {row['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a5ab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final dataset\n",
    "OUTPUT_PATH = '/content/drive/MyDrive/HIN_SIN/dataset/SinhalaEnglish_final.csv'\n",
    "# Or for local: OUTPUT_PATH = '../dataset/SinhalaEnglish_final.csv'\n",
    "\n",
    "output_df.to_csv(OUTPUT_PATH, index=False, encoding='utf-8')\n",
    "print(f\"Saved final dataset to: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a40c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset documentation (datacard)\n",
    "datacard = f\"\"\"\n",
    "# Sinhala-English Code-Mixed Cyberbullying Dataset\n",
    "\n",
    "## Overview\n",
    "This dataset contains Sinhala-English code-mixed text samples labeled for cyberbullying detection.\n",
    "It was created by translating a Hindi-English code-mixed cyberbullying dataset.\n",
    "\n",
    "## Dataset Statistics\n",
    "- **Total samples**: {len(output_df)}\n",
    "- **Non-bullying (0)**: {label_counts[0]} ({label_counts[0]/len(output_df):.1%})\n",
    "- **Bullying (1)**: {label_counts[1]} ({label_counts[1]/len(output_df):.1%})\n",
    "\n",
    "## Creation Pipeline\n",
    "1. **Source**: Hindi-English code-mixed cyberbullying dataset\n",
    "2. **Translation**: Hindi ‚Üí Sinhala using IndicTrans2\n",
    "3. **Code-mixing preservation**: English tokens preserved using language detection\n",
    "4. **Quality filtering**: XLM-RoBERTa zero-shot classification for label consistency\n",
    "5. **Human validation**: Partial manual validation with inter-annotator agreement\n",
    "\n",
    "## File Format\n",
    "- **Format**: CSV (UTF-8 encoded)\n",
    "- **Columns**:\n",
    "  - `id`: Unique identifier\n",
    "  - `text`: Sinhala-English code-mixed text\n",
    "  - `label`: Binary label (0 = non-bullying, 1 = bullying)\n",
    "\n",
    "## Labels\n",
    "- **0 (Non-bullying)**: Positive, neutral, or supportive content\n",
    "- **1 (Bullying)**: Toxic, offensive, or cyberbullying content\n",
    "\n",
    "## Usage\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('SinhalaEnglish_final.csv', encoding='utf-8')\n",
    "```\n",
    "\n",
    "## Citation\n",
    "[Add your citation here]\n",
    "\n",
    "## License\n",
    "[Add license information]\n",
    "\n",
    "## Created\n",
    "{datetime.now().strftime('%Y-%m-%d')}\n",
    "\"\"\"\n",
    "\n",
    "# Save datacard\n",
    "DATACARD_PATH = '/content/drive/MyDrive/HIN_SIN/dataset/README.md'\n",
    "with open(DATACARD_PATH, 'w', encoding='utf-8') as f:\n",
    "    f.write(datacard)\n",
    "print(f\"Saved dataset documentation to: {DATACARD_PATH}\")\n",
    "print(datacard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb535d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metadata JSON\n",
    "metadata = {\n",
    "    \"dataset_name\": \"Sinhala-English Code-Mixed Cyberbullying Dataset\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"created_date\": datetime.now().isoformat(),\n",
    "    \"source_dataset\": \"Hindi-English Code-Mixed Cyberbullying Dataset\",\n",
    "    \"statistics\": {\n",
    "        \"total_samples\": int(len(output_df)),\n",
    "        \"non_bullying_count\": int(label_counts[0]),\n",
    "        \"bullying_count\": int(label_counts[1]),\n",
    "        \"class_balance\": round(label_counts[1] / len(output_df), 3)\n",
    "    },\n",
    "    \"pipeline\": [\n",
    "        \"IndicTrans2 translation (Hindi ‚Üí Sinhala)\",\n",
    "        \"Code-mixing preservation\",\n",
    "        \"XLM-RoBERTa quality filtering\",\n",
    "        \"Human validation\"\n",
    "    ],\n",
    "    \"languages\": [\"Sinhala\", \"English\"],\n",
    "    \"task\": \"Binary classification (cyberbullying detection)\"\n",
    "}\n",
    "\n",
    "METADATA_PATH = '/content/drive/MyDrive/HIN_SIN/dataset/metadata.json'\n",
    "with open(METADATA_PATH, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "print(f\"Saved metadata to: {METADATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35317795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ DATASET CREATION COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä Final Dataset:\n",
    "   - File: SinhalaEnglish_final.csv\n",
    "   - Samples: {len(output_df)}\n",
    "   - Labels: 0 (non-bullying), 1 (bullying)\n",
    "\n",
    "üìÅ Output Files:\n",
    "   - dataset/SinhalaEnglish_final.csv (main dataset)\n",
    "   - dataset/README.md (documentation)\n",
    "   - dataset/metadata.json (metadata)\n",
    "\n",
    "‚úÖ Pipeline completed:\n",
    "   1. Translation (Hindi ‚Üí Sinhala)\n",
    "   2. Code-mixing preservation\n",
    "   3. Quality filtering\n",
    "   4. Human validation\n",
    "   5. Finalization\n",
    "\n",
    "üî¨ Ready for:\n",
    "   - Model training\n",
    "   - Research publication\n",
    "   - Benchmarking\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
